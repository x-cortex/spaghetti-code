import gradio as gr
from rag import get_response
import os
import json
from datetime import datetime


# Function to handle chat and store data
def chat_interface(user_input, recipient, chat_history):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # Use the current time

    # Get the response from the model based on the user input
    response_data = get_response(
        chat_message=user_input,
        recipient=recipient,
        chat_history=chat_history,
        timestamp=timestamp,
    )

    return response_data


# Define Gradio Interface with user_input, recipient, and chat_history as inputs
iface = gr.Interface(
    fn=chat_interface,
    inputs=[
        gr.Textbox(
            lines=2, placeholder="Enter your message here...", label="User Message"
        ),
        gr.Textbox(
            placeholder="Enter recipient name",
            label="Recipient",
            value="default_recipient",
        ),
        gr.Textbox(
            lines=5, placeholder="Chat history (optional)", label="Chat History"
        ),
    ],
    outputs=gr.Textbox(label="AI Response"),
    title="LangChain & LangGraph Chatbot",
    description="Enter a message, recipient, and optional chat history to receive a response generated by the local LLaMA model using LangChain and LangGraph.",
    theme="default",
)

if __name__ == "__main__":
    iface.launch()
